// configuration of a DQNTrainer
{
    "logger": {
        "level": "info", //40
        // "console": "False",
    },

    "train": {
        "startModel": "/mnt/e/AShareSample/S2d32X18Y4F518x1.resnet50.h5",
        "baseModel": "sliced2d",
        // "trainableLayers": ["*"], // trainable layers, '*' means all, i.e. ['F88.Dense*', 'VClz66from512.2of2']

        "dirSamples": "/mnt/e/AShareSample/RFrm2dImg32x18C8_ETF2013-2020", // or "sampleFiles": [...],
        "preBalanced": "false",
        "gamma": 0.01,

        "CPU": {
            "batchSize": 64,
            "batchesPerTrain": 32,
            "poolReuses": 0,
            "initEpochs": 2,
            "startLR": 0.005, // start learningRate
            // "lossDiffStop": 5, // loss reduce 5% difference to quit current epoch
            "lossStop": 0.25, // "lossStop": 0.1, --- loss value less than 0.1 to quit current epoch
        },
        
        "GPU": {
            "batchSize": 128,
            "batchesPerTrain": 64, // 512x64 for GTX1050/2G, 512x128 for GTX1060/4G
            "recycles": 1, // takes system memory instead of VRAM
            "initEpochs": 8, // 8 when the model is not well trained, 4 when trained and try to cover larger dataset
            "startLR": 0.01,

            "models": [
                { 
                    "model":"GTX 1650",
                    "batchSize": 400, // float32 can reach 100x64, float16 can reach 400x64
                    "batchesPerTrain": 64,
                },
            ]
        },
    },
}
