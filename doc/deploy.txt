TRANINER_URL=http://tc.syscheme.com:10088/trainer
MODEL=VGG16d1.S1548I4A3
WGET="wget --user=trainer --password=r654321"

mkdir -p ~/.ssh
${WGET} -O- ${TRANINER_URL}/authorized_keys >> ~/.ssh/authorized_keys

mkdir ~/.pip/
cat > ~/.pip/pip.conf
[global]
  trusted-host =  mirrors.aliyun.com
  index-url = https://mirrors.aliyun.com/pypi/simple

apt install -y cron htop tree lsof git nano

pip3 install json-cfg websocket websocket-client pathlib matplotlib requests demjson filelock h5py &
pip3 list|grep tensorflow
pip3 install tensorflow-gpu==1.12

WKSPACE=$(realpath ~/wkspaces)
mkdir ${WKSPACE}
cd ${WKSPACE}
git clone https://github.com/syscheme/HyperPixiu.git
cd ${WKSPACE}/HyperPixiu/
git pull
git checkout -f gym
git pull

mkdir -p ${WKSPACE}/HyperPixiu/ETF
cd ${WKSPACE}//HyperPixiu/ETF
${WGET} -O- ${TRANINER_URL}/RFrames.tar.bz2 |tar xfvj - 

mkdir -p ${WKSPACE}/HyperPixiu/ETF/out/${MODEL}
cd ${WKSPACE}/HyperPixiu/ETF/out/${MODEL}
${WGET} -O- ${TRANINER_URL}/VGG16d1.S1548I4A3.tar.bz2 |tar xfvj - 
mv ${MODEL}.model.json model.json
mv ${MODEL}.weights.h5 weights.h5

cd /tmp/

scp -r -P 49058 root@111.44.254.182:/tmp/VGG16d1*.tar.bz2 /tmp/
   cd /tmp/
   tar xfvj VGG16d1.S1548I4A3.tar.bz2 
   cd tmp/VGG16d1.S1548I4A3/
   rm -rf *.log tb
   
   cp VGG16d1.S1548I4A3.weights.h5 ~/wkspaces/HyperPixiu/out/VGG16d1.S1548I4A3/weights.h5

/tmp/VGG16d1.S1548I4A3.weights.h5 ~/wkspaces/HyperPixiu/out/VGG16d1.S1548I4A3/weights.h5

cd ${WKSPACE}/HyperPixiu/

   49  cd ~/wkspaces/HyperPixiu/
   50  ./run.sh src/hpGym/DQNTrainer.py -f conf/DQNTrainer_VGG16d1.json &
   54  mv out/DQNTrainer_3865/VGG16d1.S1548I4A3.model.json out/VGG16d1.S1548I4A3/model.json

   57  ./run.sh src/hpGym/DQNTrainer.py -f conf/DQNTrainer_VGG16d1.json &
   63  crontab -l
   64  /root/wkspaces/HyperPixiu/src/launch/TcTrainer.sh &

   71  top
   72  vi src/launch/TcTrainer.sh 
   73  vi conf/DQNTrainer_U16TfGpu.json 
   74  /root/wkspaces/HyperPixiu/src/launch/TcTrainer.sh &
   75  /root/wkspaces/HyperPixiu/src/launch/TcTrainer.sh &
   76  cd ~/wkspaces/HyperPixiu
   77  cd "~/wkspaces/HyperPixiu"
   78  cd $(realpath ~/wkspaces/HyperPixiu)
   79  git status
   80  git diff
   81  git status
   82  git checkout -f
   83  git pull
   84  /root/wkspaces/HyperPixiu/src/launch/TcTrainer.sh &
   85  top
   86  vi conf/DQNTrainer_U16TfGpu.json 
   87  top
   88  ps aux|grep python
   89  kill -9 15013
   90  ./run.sh src/hpGym/DQNTrainer.py -f conf/DQNTrainer_U16TfGpu.json &
   91  cat conf/DQNTrainer_U16TfGpu.json 
   92  top
   93  history




on master node
=================
mkdir -p /mnt/data/redis
echo "" > /mnt/data/redis/users.acl
echo "aclfile /data/users.acl" > /mnt/data/redis/redis.conf
echo "dir /data" >> /mnt/data/redis/redis.conf
docker run --name=redis6 -d --restart=always -p 15379:6379 -v /mnt/data/redis:/data redis redis-server /data/redis.conf
redis-cli -p 15379
127.0.0.1:15379> config set requirepass <passwd>
127.0.0.1:15379> ACL SETUSER hpxwkr +set
127.0.0.1:15379> ACL SETUSER hpxwkr +get
127.0.0.1:15379> ACL SETUSER hpxwkr +@pubsub
127.0.0.1:15379> ACL SETUSER hpxwkr on >hpxwkr
127.0.0.1:15379> ACL save

non-docker-mode to start celery:
 1) start the master with concurrency=1: 
      cd ${HPXPROJ}; echo "rm -rf /tmp/wkr.sinaMaster.log; src/dapps/startWorker.sh sinaMaster -l DEBUG -c 1 -Q master,celery" |at now
 2) optional start a crawler with concurrency=1:
      cd ${HPXPROJ}; echo "rm -rf /tmp/wkr.sinaCrawler.log; src/dapps/startWorker.sh sinaCrawler -l DEBUG -c 1 -Q crawler,celery" |at now
 2) start a beat:
      cd ${HPXPROJ}/src; echo "celery -A dapps.sinaMaster beat -l DEBUG --logfile /tmp/beat.log" |at now

https://hub.docker.com/_/celery
start celery worker via docker
DOCKER_HOST_IP=$(ip address show dev docker0 |grep -o 'inet [0-9\.]*' |cut -d ' ' -f2)

# no need to specify the out-side port 15379, container celery is able to connect to 6379 of container redis6
CELERY_COMMON_OPT=--link redis6:redis -e CELERY_BROKER_URL=redis://redis -v /home/wkspaces/hpx_template:/hpx_template -d celery
docker run ${CELERY_COMMON_OPT} --name beat "cd /hpx_template/src; celery dapps.sinaMaster beat -l INFO"
docker run ${CELERY_COMMON_OPT} --name beat "cd /hpx_template/src; celery dapps.sinaMaster worker -l INFO"

the result would be like
[root@tc2 hpx_template]$ cat /mnt/data/redis/users.acl 
user ahs on #ca8280a415746b39200ea7a5e7e6388c4a3ddd4414901542cdc9a1830f02750e ~* +@all
user default on #7fed46305d7a75700bbce9186f838ada36c3876d1ce3078dcbb057e35e336e48 ~* +@all -@admin
user hpxwkr on #7fed46305d7a75700bbce9186f838ada36c3876d1ce3078dcbb057e35e336e48 ~* -@all +@pubsub +set +get


on worker node
=================
mount fs by taking sync_write but allow read-cache
sshfs -o sshfs_sync -p <sshport> <user>@<master-host>:/mnt/data/hpwkspaces/users/<user> /mnt/s
non-docker-mode to start celery:
 1) start a crawler with default concurrency= number of CPUs:
      cd ${HPXPROJ}; echo "rm -rf /tmp/wkr.sinaCrawler.log; src/dapps/startWorker.sh sinaCrawler -l DEBUG -Q crawler,celery" |at now

 or start by script:
     root@~# cat ~/tasks/runWorker.sh
     #!/bin/bash
     WORKER=$(cat /mnt/s/.ssh/id_rsa.pub |cut -d ' ' -f3|cut -d '@' -f1)

     mkdir  ~/wkspaces; cd ~/wkspaces
     ln -sf /mnt/s/hpx_publish .
     ln -sf /mnt/w/archived hpx_archived
     rsync -auv --delete --exclude-from /mnt/w/hpx_template/dist/rsync_excl.txt /mnt/w/hpx_template .

     cd hpx_template
     echo "rm -rf /tmp/wkr.sinaCrawler.log; src/dapps/startWorker.sh sinaCrawler -l DEBUG -Q crawler,celery -n ${WORKER}@%h" |at now

>>> import paramiko
>>> ssh = paramiko.SSHClient()
>>> ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
>>> ssh.connect('tc2.syscheme.com', port=10022, username='root')
>>> from scp import SCPClient
>>> with SCPClient(ssh.get_transport()) as scp:
...     scp.get('/tmp/beat.log')

or
from scp import SCPClient
from scp import SCPClient
import paramiko
with paramiko.SSHClient() as ssh:
     ssh.set_missing_host_key_policy(paramiko.AutoAddPolicy())
     ssh.connect('tc2.syscheme.com', port=10022, username='root')
     with SCPClient(ssh.get_transport()) as scp:
          scp.get('/tmp/aaaa.log')
